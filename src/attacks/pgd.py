"""
PGD Attack Implementation for Whisper ASR.

Adversarial examples are generated by iterating over the input audio tensor
to maximize the loss (minimize confidence in the correct transcription).
"""

import torch
import torch.nn as nn
import numpy as np


class PGDAttack:
    """
    Projected Gradient Descent Attack for Whisper.

    Attributes:
        model (torch.nn.Module): The Whisper model.
        loss_fn (torch.nn.Module): Loss function (CrossEntropy).
        epsilon (float): Maximum perturbation magnitude (L_infinity norm).
        alpha (float): Step size for gradient update.
        num_steps (int): Number of optimization iterations.
    """

    def __init__(
        self,
        model,
        epsilon=0.01,
        alpha=0.002,
        num_steps=10,
        loss_fn=None,
    ):
        self.model = model
        self.epsilon = epsilon
        self.alpha = alpha
        self.num_steps = num_steps
        
        # Default to CrossEntropy loss for ASR
        if loss_fn is None:
            self.loss_fn = nn.CrossEntropyLoss()
        else:
            self.loss_fn = loss_fn

    def __call__(self, audio, target_label, input_length):
        """
        Generate adversarial audio.

        Args:
            audio (torch.Tensor): Clean audio tensor of shape (1, T).
            target_label (torch.Tensor): Target token indices (int64).
            input_length (int): Length of the audio segment to consider (for padding if needed).

        Returns:
            torch.Tensor: Adversarial audio tensor.
        """
        
        # Ensure model is in eval mode for attack
        self.model.eval()
        
        # Create a copy of the audio to perturb
        # Use requires_grad=True to track gradients for the attack
        adv_audio = audio.clone().detach().requires_grad_(True)
        
        # Initialize perturbation vector
        perturbation = torch.zeros_like(adv_audio)
        
        for step in range(self.num_steps):
            # Forward pass
            logits = self.model(adv_audio)
            
            # Compute Loss (Negative Log Likelihood)
            # We assume logits are batch_size x vocab_size
            loss = self.loss_fn(logits, target_label)
            
            # Check if loss is NaN/Inf
            if torch.isnan(loss) or torch.isinf(loss):
                break
            
            # Backward pass to compute gradients w.r.t input
            self.model.zero_grad()
            loss.backward(retain_graph=True)
            
            # Get gradient sign
            grad = adv_audio.grad.data
            
            # Update perturbation: v = v + alpha * sign(grad)
            perturbation.data = perturbation.data + self.alpha * torch.sign(grad)
            
            # Project perturbation back into the epsilon-ball (L-infinity norm constraint)
            perturbation.data = torch.clamp(
                perturbation, 
                -self.epsilon, 
                self.epsilon
            )
            
            # Clamp perturbation to be safe for audio range [-1, 1]
            perturbation.data = torch.clamp(
                perturbation, 
                -1 - adv_audio.data, 
                1 - adv_audio.data
            )
            
            # Update adversarial audio
            adv_audio.data = adv_audio.data + perturbation
            
            # Final clamp to ensure audio stays in valid range
            adv_audio.data = torch.clamp(adv_audio.data, -1.0, 1.0)

        return adv_audio.detach()


def clip(val, min_val, max_val):
    """Helper to clip a tensor to a range."""
    return torch.clamp(val, min_val, max_val)

