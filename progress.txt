- Week 1: Created requirements.txt with torch, whisper, speechbrain, librosa, etc.
- Initial setup prepared for GPU/CUDA usage.
- Created `src/data/` directory structure.
- Implemented `audio_loader.py` for 16kHz resampling and normalization.
- Added `download_data.py` to handle dataset acquisition (LibriSpeech/CommonVoice).
- Week 2: Completed baseline performance evaluation notebook. Initialized Whisper model and calculated WER/CER on clean LibriSpeech data.
- Week 2: Implemented full `src/attacks/pgd.py` logic including gradient computation, clipping, and optimization loop to enable PGD experimentation.
- Week 1/2: Created `notebooks/01_explore_dataset.ipynb` to visualize waveforms, analyze duration, and check normalization parameters.
