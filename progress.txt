- Week 1: Created requirements.txt with torch, whisper, speechbrain, librosa, etc.
- Initial setup prepared for GPU/CUDA usage.
- Created `src/data/` directory structure.
- Implemented `audio_loader.py` for 16kHz resampling and normalization.
- Added `download_data.py` to handle dataset acquisition (LibriSpeech/CommonVoice).
- Week 2: Completed baseline performance evaluation notebook. Initialized Whisper model and calculated WER/CER on clean LibriSpeech data.
- Week 2: Implemented full `src/attacks/pgd.py` logic including gradient computation, clipping, and optimization loop to enable PGD experimentation.
- Week 1/2: Created `notebooks/01_explore_dataset.ipynb` to visualize waveforms, analyze duration, and check normalization parameters.
- Week 2: Created `notebooks/02_performance_evaluation.ipynb` for baseline metrics.
- Week 2: PGD Implementation done. Created `notebooks/03_pgd_attack.ipynb`.
- Week 4: Implemented `notebooks/04_uap_training.ipynb` with UAP initialization, gradient accumulation loop, and projection logic. Save utility included.
