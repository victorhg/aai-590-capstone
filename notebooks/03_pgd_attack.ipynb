{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from src.models.whisper_wrapper import WhisperASRWithAttack\n",
    "from src.attacks.pgd import PGDAttack\n",
    "from src.data.audio_loader import load_audio\n",
    "from src.data.download_data import download_librispeech_sample\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3677111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "data_root = os.path.join(os.getcwd(), '..', 'data')\n",
    "dataset_path = download_librispeech_sample(data_root)\n",
    "\n",
    "# Find a file\n",
    "files = glob.glob(os.path.join(dataset_path, \"**\", \"*.flac\"), recursive=True)\n",
    "if not files:\n",
    "    raise RuntimeError(\"No audio files found! Run download first.\")\n",
    "\n",
    "target_file = files[0]\n",
    "print(f\"Attacking file: {target_file}\")\n",
    "\n",
    "# Load audio\n",
    "audio = load_audio(target_file).to(device)\n",
    "print(f\"Audio shape: {audio.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize Model & Processor\n",
    "wrapper = WhisperASRWithAttack(device=device)\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "def decode_output(logits):\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "# Baseline transcription\n",
    "with torch.no_grad():\n",
    "    res_clean = wrapper(audio)\n",
    "    transcription_clean = decode_output(res_clean.logits)\n",
    "    \n",
    "print(f\"Original Transcription: '{transcription_clean}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Perform PGD Attack\n",
    "# Epsilon 0.02 is approx -34dB relative to max amplitude 1.0 (roughly)\n",
    "attacker = PGDAttack(wrapper, epsilon=0.02, alpha=0.002, num_iter=30) \n",
    "\n",
    "print(\"Running PGD...\")\n",
    "adv_audio = attacker.generate(audio)\n",
    "\n",
    "# 4. Evaluate\n",
    "from src.attacks.pgd import compute_snr\n",
    "snr = compute_snr(audio.cpu().numpy(), adv_audio.cpu().numpy())\n",
    "\n",
    "with torch.no_grad():\n",
    "    res_adv = wrapper(adv_audio)\n",
    "    transcription_adv = decode_output(res_adv.logits)\n",
    "\n",
    "print(f\"Adversarial Transcription: '{transcription_adv}'\")\n",
    "print(f\"SNR: {snr:.2f} dB\")\n",
    "\n",
    "# 5. Play Audio (Optional)\n",
    "from IPython.display import Audio, display\n",
    "print(\"Adversarial Audio:\")\n",
    "display(Audio(adv_audio.cpu().numpy(), rate=16000))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
