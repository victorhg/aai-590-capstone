{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Baseline Performance Evaluation\n",
    "\n",
    "This notebook establishes the ground truth performance of Whisper on clean LibriSpeech data before applying adversarial attacks.\n",
    "\n",
    "**Goals:**\n",
    "1. Load LibriSpeech `test-clean` data.\n",
    "2. Initialize Whisper model.\n",
    "3. Transcribe clean audio.\n",
    "4. Calculate WER and CER using `jiwer`.\n",
    "5. Log results for later comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from jiwer import wer, cer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data.download_data import get_dataset_path\n",
    "from data.audio_loader import load_audio, normalize_audio\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "We need to ensure reproducibility and check device availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model Selection (Small-V3 is fast enough for testing, Large-V2 for quality)\n",
    "# We'll use small-v3 for faster iteration during initial baseline checks\n",
    "model_name = \"openai/whisper-small\"\n",
    "print(f\"Loading Whisper model: {model_name}\")\n",
    "\n",
    "import whisper\n",
    "model = whisper.load_model(model_name, device=device)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "We load the LibriSpeech `test-clean` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume download_data.py has created the path structure\n",
    "dataset_root = get_dataset_path('librispeech')\n",
    "print(f\"Dataset root: {dataset_root}\")\n",
    "\n",
    "# LibriSpeech structure: ./LibriSpeech/test-clean/\n",
    "test_clean_path = Path(dataset_root) / 'LibriSpeech' / 'test-clean'\n",
    "\n",
    "if not test_clean_path.exists():\n",
    "    raise FileNotFoundError(f\"Test-clean directory not found at {test_clean_path}.\")\n",
    "\n",
    "print(f\"Found {len(list(test_clean_path.rglob('*.flac')))} audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Transcription Loop\n",
    "\n",
    "Iterate through audio files, transcribe, and compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "base_wer = 0\n",
    "base_cer = 0\n",
    "\n",
    "audio_files = list(test_clean_path.rglob('*.flac'))[:50] # Limit to 50 for initial baseline\n",
    "\n",
    "print(f\"Processing {len(audio_files)} samples...\")\n",
    "\n",
    "for audio_path in tqdm(audio_files):\n",
    "    # 1. Load Audio\n",
    "    # Whisper expects 16kHz input\n",
    "    audio_array, sample_rate = load_audio(str(audio_path))\n",
    "    \n",
    "    # 2. Transcribe\n",
    "    # Use small model settings for faster processing\n",
    "    result = model.transcribe(\n",
    "        audio_array, \n",
    "        language='en',\n",
    "        fp16=False if device == 'cpu' else True\n",
    "    )\n",
    "    \n",
    "    # 3. Extract Ground Truth (LibriSpeech filenames often contain the text)\n",
    "    # Example: 119 / 128104 / 128104-0000.wav -> \"119 128104 128104-0000\"\n",
    "    base_filename = audio_path.stem\n",
    "    text_segments = base_filename.split('-')\n",
    "    # Clean up numbers and whitespace\n",
    "    ground_truth = \" \".join(text_segments).strip()\n",
    "    \n",
    "    # 4. Metrics\n",
    "    transcribed_text = result['text'].strip().lower()\n",
    "    \n",
    "    current_wer = wer(ground_truth, transcribed_text)\n",
    "    current_cer = cer(ground_truth, transcribed_text)\n",
    "    \n",
    "    results.append({\n",
    "        'audio_path': str(audio_path.relative_to(test_clean_path.parent.parent.parent)),\n",
    "        'ground_truth': ground_truth,\n",
    "        'transcription': transcribed_text,\n",
    "        'wer': current_wer,\n",
    "        'cer': current_cer\n",
    "    })\n",
    "    \n",
    "    base_wer += current_wer\n",
    "    base_cer += current_cer\n",
    "\n",
    "print(\"\\n--- Baseline Results (Clean) ---\")\n",
    "print(f\"WER: {base_wer / len(results):.4f}\")\n",
    "print(f\"CER: {base_cer / len(results):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Results\n",
    "\n",
    "Save baseline metrics for later comparison with adversarial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results\n",
    "with open('results/baseline_clean_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "metrics = {'mean_wer': base_wer / len(results), 'mean_cer': base_cer / len(results)}\n",
    "with open('results/baseline_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Baseline metrics saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
