{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc55d732",
   "metadata": {},
   "source": [
    "# 06: Adversarial Jamming: Smart Noise vs. Loud Noise\n",
    "\n",
    "**Hypothesis**: A universally trained perturbation (UAP) acts as a more efficient \"jammer\" than random white noise. It should degrade transcription accuracy at lower volumes (higher SNR) compared to random noise.\n",
    "\n",
    "**Scenario**: We simulate an \"Over-the-Air\" attack by digitally mixing the noise into the audio track, as if it were playing in the background of a room.\n",
    "\n",
    "## Goals\n",
    "1. Load the trained UAP (from Notebook 04).\n",
    "2. Compare it against Gaussian (White) Noise.\n",
    "3. Measure Transcription WER across different \"loudness\" levels (SNR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from jiwer import wer\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from src.data.audio_loader import load_audio, get_audio_duration\n",
    "from src.data.download_data import download_librispeech_sample\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dec738",
   "metadata": {},
   "source": [
    "## 1. Setup: Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24952086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Victim Model (Standard Whisper)\n",
    "model_name = \"openai/whisper-base\"\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "print(\"Victim model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef86551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a clean audio sample\n",
    "data_root = os.path.join(os.getcwd(), '..', 'data')\n",
    "dataset_path = download_librispeech_sample(data_root)\n",
    "files = glob.glob(os.path.join(dataset_path, \"**\", \"*.flac\"), recursive=True)\n",
    "\n",
    "if not files:\n",
    "    raise RuntimeError(\"No audio files found! Run Notebook 01 first.\")\n",
    "\n",
    "sample_path = files[0]\n",
    "clean_audio = load_audio(sample_path).to(device)\n",
    "\n",
    "# Ensure shape is (1, samples)\n",
    "if clean_audio.ndim == 1:\n",
    "    clean_audio = clean_audio.unsqueeze(0)\n",
    "\n",
    "print(f\"Loaded audio: {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38cd4e",
   "metadata": {},
   "source": [
    "## 2. Load the Universal Adversarial Perturbation (UAP)\n",
    "We attempt to load `uap.pt`. If it doesn't exist (because you haven't run Notebook 04 yet), we generate a random one for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uap_path = os.path.join(os.getcwd(), 'uap.pt')\n",
    "\n",
    "if os.path.exists(uap_path):\n",
    "    print(\"Loading trained UAP...\")\n",
    "    uap_noise = torch.load(uap_path, map_location=device)\n",
    "else:\n",
    "    print(\"WARNING: UAP file not found. Generating RANDOM UAP for demo purposes.\")\n",
    "    # Generate a random perturbation of 10 seconds (avg length)\n",
    "    # In reality, this should be your trained vector\n",
    "    uap_noise = torch.randn(1, 16000 * 10).to(device) * 0.05\n",
    "\n",
    "# Prepare UAP: Tile it to match audio length if necessary\n",
    "def match_length(noise, target_len):\n",
    "    if noise.shape[1] >= target_len:\n",
    "        return noise[:, :target_len]\n",
    "    else:\n",
    "        repeat_times = (target_len // noise.shape[1]) + 1\n",
    "        return noise.repeat(1, repeat_times)[:, :target_len]\n",
    "\n",
    "uap_aligned = match_length(uap_noise, clean_audio.shape[1])\n",
    "print(f\"UAP Shape aligned: {uap_aligned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9324d4",
   "metadata": {},
   "source": [
    "## 3. Define Mixing Function (SNR)\n",
    "We mix noise at a specific Signal-to-Noise Ratio (dB). \n",
    "- **High SNR (e.g., 40dB)** = Quiet Noise (Hard to hear)\n",
    "- **Low SNR (e.g., 10dB)** = Loud Noise (Very obvious)\n",
    "\n",
    "We want to see the UAP break the model at **High SNR**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af56ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_snr(clean, noise, target_snr_db):\n",
    "    \"\"\"\n",
    "    Scale noise to achieve target SNR.\n",
    "    SNR = 10 * log10(P_signal / P_noise)\n",
    "    P_noise_target = P_signal / 10^(SNR/10)\n",
    "    \"\"\"\n",
    "    # Calculate power\n",
    "    p_signal = torch.mean(clean ** 2)\n",
    "    p_noise = torch.mean(noise ** 2)\n",
    "    \n",
    "    if p_noise == 0:\n",
    "        return noise\n",
    "        \n",
    "    # Calculate scaling factor\n",
    "    p_noise_target = p_signal / (10 ** (target_snr_db / 10))\n",
    "    scale = torch.sqrt(p_noise_target / p_noise)\n",
    "    \n",
    "    return noise * scale\n",
    "\n",
    "def transcribe(audio_tensor):\n",
    "    \"\"\"Run Whisper inference.\"\"\"\n",
    "    input_features = processor(audio_tensor.squeeze().cpu().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d014a",
   "metadata": {},
   "source": [
    "## 4. Run Experiment: Smart vs. Loud Jammer\n",
    "We iterate through SNR levels from 50dB (quiet) to 0dB (loud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_levels = [50, 40, 30, 20, 10, 5, 0] # dB\n",
    "uap_wers = []\n",
    "white_wers = []\n",
    "\n",
    "# 1. Get Baseline\n",
    "baseline_text = transcribe(clean_audio)\n",
    "print(f\"Baseline Text: {baseline_text}\\n\")\n",
    "\n",
    "for snr in snr_levels:\n",
    "    print(f\"--- Testing SNR: {snr} dB ---\")\n",
    "    \n",
    "    # A. White Noise (Random)\n",
    "    white_noise_raw = torch.randn_like(clean_audio)\n",
    "    white_noise_scaled = set_snr(clean_audio, white_noise_raw, snr)\n",
    "    audio_white = torch.clamp(clean_audio + white_noise_scaled, -1.0, 1.0)\n",
    "    \n",
    "    trans_white = transcribe(audio_white)\n",
    "    wer_white = wer(baseline_text, trans_white)\n",
    "    white_wers.append(wer_white)\n",
    "    \n",
    "    # B. UAP (Smart Noise)\n",
    "    # Note: We align UAP earlier\n",
    "    uap_scaled = set_snr(clean_audio, uap_aligned, snr)\n",
    "    audio_uap = torch.clamp(clean_audio + uap_scaled, -1.0, 1.0)\n",
    "    \n",
    "    trans_uap = transcribe(audio_uap)\n",
    "    wer_uap = wer(baseline_text, trans_uap)\n",
    "    uap_wers.append(wer_uap)\n",
    "    \n",
    "    print(f\"White Noise WER: {wer_white:.2f} | UAP WER: {wer_uap:.2f}\")\n",
    "    if wer_uap > 0.8: \n",
    "        print(f\"  -> UAP JAMMED at {snr}dB: '{trans_uap}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b544a5",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340842c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(snr_levels, white_wers, marker='o', label='White Noise (Random)', linestyle='--')\n",
    "plt.plot(snr_levels, uap_wers, marker='x', label='UAP (Smart Jammer)', linewidth=2, color='red')\n",
    "\n",
    "plt.title('Jamming Efficiency: UAP vs. Random Noise')\n",
    "plt.xlabel('SNR (dB) - Higher is Quieter Noise')\n",
    "plt.ylabel('Word Error Rate (WER)')\n",
    "plt.gca().invert_xaxis() # We want x-axis to go from Quiet (50) to Loud (0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
