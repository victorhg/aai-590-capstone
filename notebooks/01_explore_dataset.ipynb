{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook visualizes the audio data to:\n",
    "1.  Confirm audio is loaded correctly (16kHz, normalized).\n",
    "2.  Analyze duration distribution (determines optimal UAP vector length).\n",
    "3.  Visualize waveforms and Mel-spectrograms.\n",
    "4.  Check amplitude statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Add src to path to import modules\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from src.data.audio_loader import load_audio, get_audio_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Verify Audio Pipeline\n",
    "\n",
    "We load a few sample audio files to ensure the `audio_loader.py` functions work as expected (16kHz resampling, float32 normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from src.data.download_data import download_librispeech_sample\n",
    "\n",
    "# 1. Download/Locate Data\n",
    "# We use a 'data' directory in the project root\n",
    "data_root = os.path.join(os.getcwd(), '..', 'data') \n",
    "dataset_path = download_librispeech_sample(data_root)\n",
    "print(f\"Dataset location: {dataset_path}\")\n",
    "\n",
    "# 2. Find all .flac files\n",
    "sample_paths = glob.glob(os.path.join(dataset_path, \"**\", \"*.flac\"), recursive=True)\n",
    "print(f\"Found {len(sample_paths)} audio files.\")\n",
    "\n",
    "if len(sample_paths) > 0:\n",
    "    print(f\"Sample: {sample_paths[0]}\")\n",
    "else:\n",
    "    print(\"WARNING: No audio files found. Check download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Duration Distribution Analysis\n",
    "\n",
    "Whisper processes fixed-length inputs (e.g., 30s chunks). We need to know the distribution of our data to decide how to handle variable-length utterances.\n",
    "- If audio > 30s: We will tile the perturbation or crop the audio.\n",
    "- If audio < 30s: We need to handle short sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for path in sample_paths:\n",
    "    dur = get_audio_duration(path)\n",
    "    durations.append(dur)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(durations, bins=30, edgecolor='black')\n",
    "plt.axvline(x=30, color='r', linestyle='--', label='30s Threshold')\n",
    "plt.title('Distribution of Audio Utterance Durations')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Duration: {np.mean(durations):.2f}s\")\n",
    "print(f\"Max Duration: {np.max(durations):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Waveforms and Mel-Spectrograms\n",
    "\n",
    "Visualizing the Mel-spectrogram is crucial because Whisper operates on this representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel_spectrogram(audio, sr, title=\"Mel Spectrogram\"):\n",
    "    y = audio.astype(np.float32)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_waveform(audio, sr, title=\"Waveform\"):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.waveshow(audio, sr=sr)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize first sample\n",
    "if len(sample_paths) > 0:\n",
    "    audio, sr = load_audio(sample_paths[0])\n",
    "    plot_waveform(audio, sr)\n",
    "    plot_mel_spectrogram(audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Amplitude Statistics\n",
    "\n",
    "Confirm that the normalization step results in values in [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = []\n",
    "for path in sample_paths:\n",
    "    audio, sr = load_audio(path)\n",
    "    amplitudes.extend(audio.tolist())\n",
    "\n",
    "amplitudes = np.array(amplitudes)\n",
    "\n",
    "print(f\"Min: {amplitudes.min():.4f}\")\n",
    "print(f\"Max: {amplitudes.max():.4f}\")\n",
    "print(f\"Mean: {amplitudes.mean():.4f}\")\n",
    "print(f\"Std: {amplitudes.std():.4f}\")\n",
    "\n",
    "# Check for clipping (values outside [-1, 1])\n",
    "clipped_count = np.sum((amplitudes < -1.0) | (amplitudes > 1.0))\n",
    "print(f\"\\nClipped Samples: {clipped_count} ({100*clipped_count/len(amplitudes):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary for Week 1/2\n",
    "\n",
    "Based on the EDA:\n",
    "- [ ] Determine if we need to handle variable length inputs (tiling vs cropping).\n",
    "- [ ] Set the `UAP_LENGTH` constant for the attack scripts.\n",
    "- [ ] Confirm that normalization keeps data in valid range [-1, 1]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
